{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ray[data]"
      ],
      "metadata": {
        "id": "aUl14ab9TBpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r80_mE_6S6-l"
      },
      "outputs": [],
      "source": [
        "import ray\n",
        "ray.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWzPd1fYS6-n"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_url\n",
        "\n",
        "repo  = \"Francesco/insects-mytwu\"\n",
        "files = [\n",
        "    hf_hub_url(repo, \"data/test-00000-of-00001-670031141e816b9b.parquet\", repo_type=\"dataset\"),\n",
        "    hf_hub_url(repo, \"data/test-00000-of-00001-670031141e816b9b.parquet\", repo_type=\"dataset\"),\n",
        "    hf_hub_url(repo, \"data/validation-00000-of-00001-876de533d76d48c6.parquet\", repo_type=\"dataset\")\n",
        "]\n",
        "\n",
        "ds = ray.data.read_parquet(files, columns=[\"image_id\", \"image\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKSWo3JcS6-n"
      },
      "outputs": [],
      "source": [
        "print(ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow as pa\n",
        "\n",
        "def first_row_arrow(tbl: pa.Table) -> pa.Table:\n",
        "    # keep exactly one representative row per group\n",
        "    return tbl.slice(0, 1)\n",
        "\n",
        "ds = (\n",
        "    ds\n",
        "    .sort(\"image_id\")  # optional: makes which row is “first” deterministic\n",
        "    .groupby(\"image_id\")\n",
        "    .map_groups(first_row_arrow, batch_format=\"pyarrow\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "NY4KMxyL9uwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def decode_to_rgb_row(row):\n",
        "    b = row[\"image\"][\"bytes\"]  # nested in the struct\n",
        "    row[\"image\"] = np.asarray(Image.open(io.BytesIO(b)).convert(\"RGB\"), dtype=np.uint8)\n",
        "    return row\n",
        "\n",
        "ds = ds.map(decode_to_rgb_row)   # <-- row-wise map\n",
        "ds = ds.materialize()"
      ],
      "metadata": {
        "id": "p8D7bPuLT24H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds)"
      ],
      "metadata": {
        "id": "ZZWI6PaOT-9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swwYq_HhS6-o"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rows = ds.take(2)  # returns a list of dicts\n",
        "\n",
        "for i, row in enumerate(rows, 1):\n",
        "    img = row[\"image\"]            # HxWx3 uint8\n",
        "    img_id = row[\"image_id\"]\n",
        "    plt.figure()\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"image_id={img_id} (#{i})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from transformers import CLIPModel, CLIPProcessor"
      ],
      "metadata": {
        "id": "O0Gjk8qxX-oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfLDxZTsS6-q"
      },
      "outputs": [],
      "source": [
        "class EmbeddingGenerator(object):\n",
        "    def __init__(self, model_id):\n",
        "        # Load CLIP model and processor.\n",
        "        self.model = CLIPModel.from_pretrained(model_id)\n",
        "        self.processor = CLIPProcessor.from_pretrained(model_id)\n",
        "\n",
        "    def __call__(self, batch, device=\"cpu\"):\n",
        "        # Load and preprocess images.\n",
        "        images = [Image.fromarray(np.uint8(img)).convert(\"RGB\") for img in batch[\"image\"]]\n",
        "        inputs = self.processor(images=images, return_tensors=\"pt\", padding=True).to(device)\n",
        "\n",
        "        # Generate embeddings.\n",
        "        self.model.to(device)\n",
        "        with torch.inference_mode():\n",
        "            batch[\"embedding\"] = self.model.get_image_features(**inputs).cpu().numpy()\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch embeddings.\n",
        "embeddings_ds = ds.map_batches(\n",
        "    EmbeddingGenerator,\n",
        "    fn_constructor_kwargs={\"model_id\": \"openai/clip-vit-base-patch32\"},  # class kwargs\n",
        "    fn_kwargs={\"device\": \"cuda\"},  # __call__ kwargs\n",
        "    concurrency=1,\n",
        "    batch_size=128,\n",
        "    num_gpus=1,\n",
        "    accelerator_type=\"L4\",\n",
        ")"
      ],
      "metadata": {
        "id": "FYa2bpBQXs8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_ds = embeddings_ds.materialize()"
      ],
      "metadata": {
        "id": "LGWfG9U6X4Eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings_ds)"
      ],
      "metadata": {
        "id": "IlFKn4w1X6LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "37eJXGulbmCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect embeddings (float32, L2-normalized) and ids\n",
        "rows = embeddings_ds.select_columns([\"image_id\",\"embedding\"]).take_all()\n",
        "ids  = np.array([r[\"image_id\"] for r in rows])\n",
        "X    = np.stack([r[\"embedding\"] for r in rows]).astype(\"float32\")  # [N,D]\n",
        "\n",
        "# FAISS cosine ≈ inner-product if X is normalized\n",
        "import faiss\n",
        "d = X.shape[1]\n",
        "index = faiss.IndexFlatIP(d)\n",
        "index.add(X)\n",
        "\n",
        "# Query top-5 neighbors for the first 3 images\n",
        "D, I = index.search(X[:3], 5)  # D: similarity scores, I: indices\n",
        "print(ids[I], D)\n"
      ],
      "metadata": {
        "id": "6ZcPmDIGbi6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If your dataset is named `embeddings_ds`, uncomment the next line:\n",
        "# ds = embeddings_ds\n",
        "\n",
        "# Pull everything we need into memory (N=498 is tiny)\n",
        "rows = embeddings_ds.select_columns([\"image_id\", \"image\", \"embedding\"]).take_all()\n",
        "\n",
        "ids   = np.array([r[\"image_id\"] for r in rows])\n",
        "imgs  = [r[\"image\"] for r in rows]                          # list of HxWx3 uint8\n",
        "X     = np.stack([r[\"embedding\"] for r in rows]).astype(\"float32\")  # [N, D]\n",
        "\n",
        "# Normalize embeddings (safe even if already normalized)\n",
        "X /= np.linalg.norm(X, axis=1, keepdims=True) + 1e-12\n",
        "\n",
        "q_num =7\n",
        "# ---- Query = first row ----\n",
        "q_img  = imgs[q_num]\n",
        "q_id   = int(ids[q_num])\n",
        "q      = X[q_num]                                               # [D]\n",
        "sims   = X @ q                                              # cosine similarity to all images\n",
        "order  = np.argsort(-sims)                                  # descending\n",
        "neighbors_idx = [i for i in order if i != q_num][:10]           # exclude self\n",
        "\n",
        "# ---- Plot: 3x4 grid: query + 10 neighbors ----\n",
        "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Slot 0 = query\n",
        "axes[0].imshow(q_img)\n",
        "axes[0].set_title(f\"Query\\nid={q_id}\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "# Slots 1..10 = neighbors\n",
        "for k, idx in enumerate(neighbors_idx, start=1):\n",
        "    axes[k].imshow(imgs[idx])\n",
        "    axes[k].set_title(f\"NN{k}: id={int(ids[idx])}\\nsim={sims[idx]:.3f}\", fontsize=9)\n",
        "    axes[k].axis(\"off\")\n",
        "\n",
        "# Any leftover axes (e.g., slot 11) -> hide\n",
        "for j in range(1 + len(neighbors_idx), len(axes)):\n",
        "    axes[j].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QYLlijEhZs3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = os.path.join(\"/content/\", \"output\")\n",
        "embeddings_ds.write_parquet(path)"
      ],
      "metadata": {
        "id": "cCIhVPtzEiRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bcFSkPPzFK9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/drive/MyDrive/clip_output/output.zip /content/output"
      ],
      "metadata": {
        "id": "PTaR1fPgE6Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUDoXQ_9DVYs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}